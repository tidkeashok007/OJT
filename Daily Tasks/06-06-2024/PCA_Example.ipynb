{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1d939c",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990831bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "X = iris.drop(['Id','Class Label'], axis=1)\n",
    "#Y = iris.drop('Id',axis=1)\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(X)\n",
    "#pca.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f5b322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0       0.361590     -0.082269       0.856572      0.358844\n",
      "1       0.656540      0.729712      -0.175767     -0.074706\n",
      "2      -0.580997      0.596418       0.072524      0.549061\n",
      "3       0.317255     -0.324094      -0.479719      0.751121\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(pca.components_,columns=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176c554",
   "metadata": {},
   "source": [
    "# Based on these coefficients, we can calculate the PCA components for our input DataFrame X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458f0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df=(pd.DataFrame(pca.components_,columns=X.columns))\n",
    "\n",
    "# Let us calculate PC1 using coefficients that are generated\n",
    "X['PC1'] = X['SepalLengthCm']* pca_df['SepalLengthCm'][0] + X['SepalWidthCm']*pca_df['SepalWidthCm'][0]+ X['PetalLengthCm']*pca_df['PetalLengthCm'][0]+X['PetalWidthCm']* pca_df['PetalWidthCm'][0]\n",
    "\n",
    "# Let us calculate PC2\n",
    "X['PC2'] = X['SepalLengthCm']* pca_df['SepalLengthCm'][1] + X['SepalWidthCm']*pca_df['SepalWidthCm'][1]+ X['PetalLengthCm']*pca_df['PetalLengthCm'][1]+X['PetalWidthCm']* pca_df['PetalWidthCm'][1]\n",
    "\n",
    "#Let us calculate PC3\n",
    "X['PC3'] = X['SepalLengthCm']* pca_df['SepalLengthCm'][2] + X['SepalWidthCm']*pca_df['SepalWidthCm'][2]+ X['PetalLengthCm']*pca_df['PetalLengthCm'][2]+X['PetalWidthCm']* pca_df['PetalWidthCm'][2]\n",
    "\n",
    "# Let us calculate PC4\n",
    "X['PC4'] = X['SepalLengthCm']* pca_df['SepalLengthCm'][3] + X['SepalWidthCm']*pca_df['SepalWidthCm'][3]+ X['PetalLengthCm']*pca_df['PetalLengthCm'][3]+X['PetalWidthCm']* pca_df['PetalWidthCm'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d91a842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm       PC1  \\\n",
      "0              5.1           3.5            1.4           0.2  2.827136   \n",
      "1              4.9           3.0            1.4           0.2  2.795952   \n",
      "2              4.7           3.2            1.3           0.2  2.621524   \n",
      "3              4.6           3.1            1.5           0.2  2.764906   \n",
      "4              5.0           3.6            1.4           0.2  2.782750   \n",
      "..             ...           ...            ...           ...       ...   \n",
      "145            6.7           3.0            5.2           2.3  7.455360   \n",
      "146            6.3           2.5            5.0           1.9  7.037007   \n",
      "147            6.5           3.0            5.2           2.0  7.275389   \n",
      "148            6.2           3.4            5.4           2.3  7.412972   \n",
      "149            5.9           3.0            5.1           1.8  6.901009   \n",
      "\n",
      "          PC2       PC3       PC4  \n",
      "0    5.641331 -0.664277 -0.037715  \n",
      "1    5.145167 -0.846287  0.060882  \n",
      "2    5.177378 -0.618056 -0.019416  \n",
      "3    5.003599 -0.605093 -0.114676  \n",
      "4    5.648648 -0.546535 -0.101849  \n",
      "..        ...       ...       ...  \n",
      "145  5.502139 -0.463462  0.386361  \n",
      "146  4.939703 -0.763402  0.217002  \n",
      "147  5.393243 -0.511981  0.097574  \n",
      "148  5.430600  0.080108  0.002152  \n",
      "149  5.031837 -0.280447 -0.195031  \n",
      "\n",
      "[150 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674e9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461621 0.05301557 0.01718514 0.00518309]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd599965",
   "metadata": {},
   "source": [
    "# The variance ratio indicates the following:\n",
    "If we choose to replace the original four features with PC1, then we will be able to capture about 92.4% of the variance of the original variables. We will introduce some approximations by not capturing 100% of the variance of the original four\n",
    "features.\n",
    "\n",
    "If we choose to replace the original four features with PC1 and PC2, then we will capture an additional 5.3 % of the variance of the original variables.\n",
    "\n",
    "If we choose to replace the original four features with PC1, PC2, and PC3, then we will now capture a further 0.017 % of the variance of the original variables.\n",
    "\n",
    "If we choose to replace the original four features with four principal components, then we will capture 100% of the variance of the original variables (92.4 + 0.053 + 0.017 + 0.005), but replacing four original features with four principal components is meaningless as we did not reduce the dimensions at all and achieved nothing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
